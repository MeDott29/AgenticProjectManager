# Compressed Conversation Summary

- endomorphosis (2025-01-24T06:34:20.595+00:00): Added ATH🥭 to the group.
- endomorphosis (2025-01-24T06:34:23.4+00:00): https://ethglobal.com/events/agents/team?code=80z4k
- endomorphosis (2025-01-24T07:56:07.464+00:00): https://github.com/coinbase/agentkit/blob/master/cdp-langchain/examples/chatbot-python/README.md
- endomorphosis (2025-01-24T07:57:18.334+00:00): https://github.com/coinbase/agentkit/tree/master/cdp-langchain/examples/chatbot-typescript
- endomorphosis (2025-01-24T08:02:57.44+00:00): https://huggingface.co/docs/transformers.js/en/index
- endomorphosis (2025-01-24T08:03:48.372+00:00): https://github.com/whitphx/transformers.js.py
- endomorphosis (2025-01-28T20:27:08.341+00:00): today is the last day to apply to the ethglobal hackathon, have either of you two decided to work on something?
- Lizardperson (2025-01-28T21:35:31.955+00:00): Yeah, I have. Talked to Danny about it (he worked with Ethereum professionally for a long time), he said that current LLMs suck at generating Solidity code as it's under represented. So Imma make a synthetic dataset of it, fine-tune a 7b on it, see if I can get it to write better code.
- endomorphosis (2025-01-28T21:37:25.618+00:00): you have to register and attach your wallet to it.
- Lizardperson (2025-01-28T21:37:41.673+00:00): Doing that right now with coinbase
- endomorphosis (2025-01-28T21:37:43.153+00:00): the deadline is today.
- endomorphosis (2025-01-28T21:37:44.264+00:00): okay
- endomorphosis (2025-01-28T21:37:51.338+00:00): that was what I was mostly making sure of
- endomorphosis (2025-01-28T21:39:07.898+00:00): and I was going to suggest that you make the full transformers.js tts / llm / asr, and integrate into the coinbase code in python which is what they are offering the bounty for, and then reuse the pure javscript tts / llm / asr for future projects.
- endomorphosis (2025-01-28T21:39:39.65+00:00): as to whether there is solidity LLMs, I think there is a good chance there is already a finetune out there, and that you should first evaluate the ones that are out there.
- endomorphosis (2025-01-28T21:40:45.9+00:00): if you dont feel like learning javascript / typescript, there is also a python version of the code as well.
- endomorphosis (2025-01-28T21:41:04.527+00:00): https://github.com/coinbase/agentkit/blob/master/cdp-langchain/examples/chatbot-python/README.md
https://github.com/coinbase/agentkit/tree/master/cdp-langchain/examples/chatbot-typescript
- Lizardperson (2025-01-28T21:41:31.3+00:00): where do you even find these bounties? Just going through their website? Google?
- endomorphosis (2025-01-28T21:41:47.141+00:00): https://ethglobal.com/events/agents/prizes
- endomorphosis (2025-01-28T21:42:32.524+00:00): https://ethglobal.com/events/agents/prizes#nethermind
- endomorphosis (2025-01-28T21:42:48.8+00:00): this one has one that I could maybe work on the Navi 3d avatar with
- endomorphosis (2025-01-28T21:43:04.109+00:00): https://ethglobal.com/events/agents/prizes#coinbase-developer-platform
- ATH🥭 (2025-01-28T22:08:09.909+00:00): do you want me to put a company in? Cornfed Boy Incorporated
- ATH🥭 (2025-01-28T22:21:55.997+00:00): I did it!
- ATH🥭 (2025-01-28T22:22:04.027+00:00): Thanks endo
- Lizardperson (2025-01-28T22:22:19.014+00:00): Trying to write the background stuff now. Have no idea what to put in since I'm basically coming at this new.
- endomorphosis (2025-01-28T22:22:52.068+00:00): sorry, I was away for a second
- endomorphosis (2025-01-28T22:24:01.221+00:00): I see Matthew Hendricks
- endomorphosis (2025-01-28T22:24:12.602+00:00): https://ethglobal.com/events/agents/team?code=80z4k
- endomorphosis (2025-01-28T22:26:34.814+00:00): @Lizardperson do you have paypal, and does it work?
- endomorphosis (2025-01-28T22:26:46.637+00:00): or do i need to transfer money from paypal to coinbase to send to you
- Lizardperson (2025-01-28T22:27:00.256+00:00): I got paypal
- endomorphosis (2025-01-28T22:27:35.886+00:00): did you stake ethereum, do you have money in your coinbase account, and have you gotten coinbase wallet installed as a chrome extension and a phone app?
- endomorphosis (2025-01-28T22:28:17.953+00:00): I will send you another thousand tomorrow on paypal, if they are not lying to me about when the hold is done
- endomorphosis (2025-01-28T22:28:25.79+00:00): can you send me your paypal email?
- Lizardperson (2025-01-28T22:28:32.277+00:00): No idea what stake means in this context, yes to money in the acount, no to chrome extension, yes to app
- endomorphosis (2025-01-28T22:29:37.723+00:00): okay, install the coinbase wallet app, and the coinbase wallet chrome extension
- Lizardperson (2025-01-28T22:30:03.914+00:00): Oh, the app is installed and the wallet's been verified.
- endomorphosis (2025-01-28T22:33:59.002+00:00): im still waiting for you to join the team [80z4k](https://ethglobal.com/events/agents/team?code=80z4k)
- Lizardperson (2025-01-28T22:34:44.916+00:00): Gimmie a second.
- Lizardperson (2025-01-28T22:37:25.005+00:00): Did you get it?
- endomorphosis (2025-01-28T22:37:45.688+00:00): yes, I see it
- Lizardperson (2025-01-28T22:41:01.487+00:00): Cool cool
- endomorphosis (2025-01-29T04:23:05.92+00:00): https://github.com/endomorphosis/voice_kit_webgpu_cjs
- endomorphosis (2025-01-29T04:23:22.54+00:00): I know it doesn't start for a few days
- endomorphosis (2025-01-29T04:23:40.029+00:00): https://github.com/huggingface/transformers.js-examples
- ATH🥭 (2025-01-29T05:46:51.364+00:00): Moonshine runs smooth as butta on my chromebook
- endomorphosis (2025-01-29T05:48:41.83+00:00): yeah, i would like to get all three pieces running asr / tts / llm and maybe even retrieval with pglite
- endomorphosis (2025-01-29T05:49:23.886+00:00): so like we can have a mini documentation for the coinbase api in the pglite database, which is retrieved into context to try to use the API to do things with
- ATH🥭 (2025-01-29T05:52:32.885+00:00): will you include synthetic thinking data?
- endomorphosis (2025-01-29T05:58:14.12+00:00): well, the first thing i want to check is how quickly we can asyncrhonously loop or callback between transcribing, to language generation, to text to speech.
- endomorphosis (2025-01-29T05:58:57.855+00:00): at some time a while ago i made some code for asr that did naive volume detection
- endomorphosis (2025-01-29T05:59:24.855+00:00): so maybe use that to interrupt generation if the person speaks, and then continue to transcribe.
- endomorphosis (2025-01-29T05:59:47.704+00:00): and maybe maintain an audio buffer
- endomorphosis (2025-01-29T06:00:57.59+00:00): there is several thinking models it looks like, including deepseek r1 qwen 1.5 distill
- endomorphosis (2025-01-29T06:01:49.689+00:00): but generally speaking you can use the optimum cli to export a model to webgpu if there is another one out there that you want to try, or that you want to finetune near the end.
- endomorphosis (2025-01-29T06:02:15.832+00:00): but i typically dont want to fine tune as long as i can do in context learning
- Lizardperson (2025-01-29T06:33:54.214+00:00): This all sounds like front end. How are we dividing labor on this?
- endomorphosis (2025-01-29T06:38:59.834+00:00): ill figure it out in a few days, I dont know what everyone has going on, and I might be getting help from some guy at qualcomm on some python stuff
- Lizardperson (2025-01-29T06:40:52.923+00:00): I'm working on writing the PRD and SAD for the Omni-converter and trying to get the American Legal API working.
- endomorphosis (2025-01-29T06:43:37.811+00:00): okay, i dont know what PRD and SAD is, but you should focus on the american legal api stuff, and I can look at integrating the model server into the omni converter
- endomorphosis (2025-01-29T06:43:57.931+00:00): and we can also work on the transformers js  version of the model server / endpoint demultiplexer.
- endomorphosis (2025-01-29T06:45:40.525+00:00): i feel like with the people at Qualcomm and Intel all wanting to have effective local inference, getting a good reusable framework is key, and I think that having a small webnn based voice agent chrome extension that can be plug and played into a variety of APIs using RAG would be super useful.
- endomorphosis (2025-01-29T06:46:39.396+00:00): in fact part of what I was doing with the embeddings, was making them so they could be searched at the edge, and retrieved into the language model context window at the edge.
- Lizardperson (2025-01-29T06:47:29.322+00:00): Basically the requirements and technical design docs. Architecture.
- endomorphosis (2025-01-29T06:48:00.626+00:00): oh okay
- endomorphosis (2025-01-29T06:48:12.563+00:00): so how much javascript do you know btw.
- Lizardperson (2025-01-29T06:49:15.197+00:00): Effectively zilch. I'd be totally relying on Claude, stackoverflow, and trial and error.
- endomorphosis (2025-01-29T06:50:51.054+00:00): well, I consider javascript to be one of the critical languages, as it is the "language of the web", so you ought to take some time to learn it, and I think the PRD and SAD is fine to wait for now, I think focusing on both what makes money and also advances the project is the key to sustainability.
- endomorphosis (2025-01-29T06:52:03.361+00:00): I was going to effectively make the model server the thing that converts the different modelities into the language model context anyways, so you might as well wait until i finish reworking that for CUDA / OpenVino
- Lizardperson (2025-01-29T06:52:10.208+00:00): I was considering what Richard wanted (he specifically said needed that and any web APIs I could make), since Naptha, but whatever works.
- endomorphosis (2025-01-29T06:52:24.598+00:00): then you will be guaranteed to have interfaces that you can program against and test that you  are getting outputs correctly.
- endomorphosis (2025-01-29T06:53:06.873+00:00): so like for example, when parsing a pdf, there is like a pdf syntax parser which is a pain in the ass, but you can also try to parse the image of the pdfs with a vlm instead
- endomorphosis (2025-01-29T06:53:30.966+00:00): and it sometimes captures the bar graphs, and tables a little bit better than the structured pdf xml
- endomorphosis (2025-01-29T06:54:26.478+00:00): so like, just as I've had to write some code to chunk all of the large ass supreme court decisions, something will have to be written to chunk all of the pdf files, chunk the audio and keyframes from the video files, etc.
- Lizardperson (2025-01-29T06:54:55.767+00:00): I'm hesitant about using LLMs to do PDF conversion. I tried doing that locally and I found it to be horribly inefficient. But if you can think of a more efficient way to do it.
- endomorphosis (2025-01-29T06:54:57.038+00:00): and then for example, the video files need to be processed with CLAP/CLIP
- endomorphosis (2025-01-29T06:55:24.593+00:00): i have seen packages that claim to have done it effectively.
- Lizardperson (2025-01-29T06:55:31.217+00:00): Would these be arbitrary chunks or semantically connected ones?
- endomorphosis (2025-01-29T06:56:08.33+00:00): semantically connected, for example if we have a textbook of ethnobotany, being able to construct a knowledge graph of all the data inside of a scanned pdf book.
- endomorphosis (2025-01-29T06:56:46.938+00:00): and there are very good VLM based pdf deconstructors out there.
- Lizardperson (2025-01-29T06:57:03.234+00:00): Do they scale?
- endomorphosis (2025-01-29T06:57:49.568+00:00): I dont know if they scale, thats the thing, once you get to millions of samples, its about can you parallelize the code, and that is the extra bit that you do on top once you get the pipeline figured out.
- endomorphosis (2025-01-29T06:58:16.11+00:00): just as how I have been converting the documents to tokens in parallel before I even run GPU on them.
- endomorphosis (2025-01-29T06:59:59.294+00:00): also, the other reason why you should learn javascript / nodejs is because its an asyncronous event driven architecture.
- endomorphosis (2025-01-29T07:01:02.89+00:00): this means that its better able to scale the number of requests that can be fulfilled
- endomorphosis (2025-01-29T07:01:23.299+00:00): Golang is also a good language if you want to have something with memory management
- endomorphosis (2025-01-29T07:02:11.797+00:00): and you can compile golang to wasm, and run it as a lambda function either in another runtime like nodejs, or line as an AWS lambda function.
- Lizardperson (2025-01-29T07:10:05.084+00:00): I know I need to learn JS. Just never had the need to until now.
- ATH🥭 (2025-01-29T09:53:55.917+00:00): try lovable.dev
- endomorphosis (2025-01-29T17:59:45.794+00:00): https://calendar.google.com/calendar/event?action=TEMPLATE&tmeid=M3I3ZnY5NTc3amJwZjZ0Z212YTlqbjJ0YXZfMjAyNTAxMjlUMTgwMDAwWiBjX2VmOWYzZjdiYThiZDc5YTYyOGQzMGI2MjFkOWU1NjRlYjNmNDE2MDQyM2JmYWY3OWQwZTc0ZWExNDJkZThhNDlAZw&tmsrc=c_ef9f3f7ba8bd79a628d30b621d9e564eb3f4160423bfaf79d0e74ea142de8a49%40group.calendar.google.com&scp=ALL
- ATH🥭 (2025-01-29T23:28:44.734+00:00): I'm all in. XD
- endomorphosis (2025-01-29T23:30:44.051+00:00): this is shitposting for sure.
- endomorphosis (2025-01-29T23:31:12.883+00:00): do you know nodejs already ath?
- ATH🥭 (2025-01-29T23:31:42.232+00:00): Yes
- endomorphosis (2025-01-29T23:33:02.262+00:00): well, I think I would like to keep the interfaces in python as close as possible as in nodejs, but client js and the presentation layer is a whole other can of worms, and I have not yet even began with.
- endomorphosis (2025-01-29T23:34:03.164+00:00): do you think the green orb motif is a good idea, or are you able to artistically manipulate it to look a little more like the coinbase logo - as seen from in a crystal ball.
- endomorphosis (2025-01-29T23:34:35.944+00:00): and make it more like the size of a small side panel extension
- endomorphosis (2025-01-29T23:35:11.713+00:00): e.g. here is microsoft edge
- endomorphosis (2025-01-29T23:35:53.389+00:00): so lets assume that the right panel is all the screen real estate we're going to have for whatever the front end has.
- endomorphosis (2025-01-29T23:36:23.252+00:00): but instead all of the functionality is a local neural network model.
- endomorphosis (2025-01-29T23:38:24.021+00:00): i still need to look at the documentation for agent kit, but I think essentially of having the "tool use" methods of having the local llm interact with an API, but I dont know what sort of auth system i will have to navigate for this coinbase agents system.
- ATH🥭 (2025-01-30T02:51:54.174+00:00): This is the type of system I think should be built. One that minimizes resistance for non-technical individuals to be on boarded.
- ATH🥭 (2025-01-30T05:39:39.793+00:00): I like the green orb. I like whatever makes us the most money. What are we building? Is everything still up in the air?
- endomorphosis (2025-01-30T05:41:08.334+00:00): something with ASR + TTS + llm in javascript chrome extension with coinbase agent
- ATH🥭 (2025-01-30T10:58:17.285+00:00): try lovable.dev
- Lizardperson (2025-01-30T22:21:01.713+00:00): just so you guys know, I'm sick with a fever. It's not bad enough to where I can't function but I'm definitely not at 100%
- ATH🥭 (2025-01-31T03:48:48.22+00:00): I wish I could help.  I  would make you some chicken noodle soup if I could, Habibi.
- ATH🥭 (2025-01-31T04:20:58.326+00:00): this is gitingest ingested by gitingest.  https://gitingest.com/cyclotruc/gitingest
- ATH🥭 (2025-01-31T21:36:49.019+00:00): I have $200 in openAI credits from a hackathon I went to. We can use them on o3
- endomorphosis (2025-01-31T21:37:30.983+00:00): *shrug*, they're better used for working on datasets, than answering chat prompts to a chrome extension
- endomorphosis (2025-01-31T21:37:38.517+00:00): if you dont have github copilot I will pay for it for you
- endomorphosis (2025-01-31T21:38:33.214+00:00): I am going to fix up some unit testing stuff in python today, and test a processor that came in the mail, and tomorrow I'll look at this stuff with the javascript
- ATH🥭 (2025-01-31T21:38:56.117+00:00): I'll take GitHub copilot. I haven't used it since 2022
- endomorphosis (2025-01-31T21:38:57.24+00:00): considering that lizardperson doesn't know javascript, so I should have python stuff he can do instead.
- endomorphosis (2025-01-31T21:39:03.954+00:00): what have you been using?
- ATH🥭 (2025-01-31T21:39:46.405+00:00): I've tried cursor, vscode extensions ... I don't like them.
- endomorphosis (2025-01-31T21:40:08.19+00:00): well, are you used to doing test driven development then?
- ATH🥭 (2025-01-31T21:40:14.137+00:00): Nope
- ATH🥭 (2025-01-31T21:41:28.819+00:00): Write tests before write code. Got it.
- endomorphosis (2025-01-31T21:41:54.302+00:00): let me see the last thing you coded
- endomorphosis (2025-01-31T21:42:01.851+00:00): i never actually looked at yout git account
- ATH🥭 (2025-01-31T21:42:34.222+00:00): I use aider
- endomorphosis (2025-01-31T21:42:48.624+00:00): do you understand the idea that you have different modules written by different people, so you define the interfaces between them, and setup a testing harness so that you make sure that your inputs / outputs validate?
- ATH🥭 (2025-01-31T21:43:58.299+00:00): here's my last accepted pull request.  it took me around six hours to learn how the codebase worked and implement the two changes I made https://github.com/elizaOS/eliza/pull/216
- endomorphosis (2025-01-31T21:45:28.167+00:00): hmm, that really doesn't tell me anything, but i guess what i'm trying to communicate, is that all large scale software projects need tests, because they are too large to fit in a single developers head, and that is the only way to keep consistency between the modules
- ATH🥭 (2025-01-31T21:48:19.032+00:00): done. I am now a software developer that always uses TDD.
- endomorphosis (2025-01-31T21:49:07.306+00:00): okay, well, what I'm hoping to get done to day, is move the testing code to a new folder, and segregate the tests based on the hardware platform e.g. qualcomm, intel, apple, nvidia, etc. https://github.com/endomorphosis/ipfs_accelerate_py/blob/main/ipfs_accelerate_py/ipfs_accelerate.py#L1505
- endomorphosis (2025-01-31T21:49:23.74+00:00): https://github.com/endomorphosis/ipfs_accelerate_py/tree/main/test
- endomorphosis (2025-01-31T21:50:41.892+00:00): and I will eventually use this to test all the huggingface models that are exported from pytorch to onnx, so that the onnx intermediate representation can be compiled  to webassembly / web neural networks, or openvino, or qualcomm neural network, or apple's metal platform.
- endomorphosis (2025-01-31T21:51:09.56+00:00): so that when I go to build an electron app or docker container, it works on every platform.
- endomorphosis (2025-01-31T21:52:19.506+00:00): and hopefully i can use some of the template skills as few shot examples, to try to let an AI agent complete the translation of the inference code for the different hardware platforms, and get as output whatever testing errors happened during the process.
- endomorphosis (2025-01-31T21:53:20.528+00:00): https://github.com/endomorphosis/ipfs_transformers_py/blob/main/ipfs_transformers_py/ipfs_transformers.py
- endomorphosis (2025-01-31T21:53:35.028+00:00): this is what happens when you try to overload every huggingface transformers method
- endomorphosis (2025-01-31T21:53:48.257+00:00): just to give you an idea of how many transformers classes there are
- endomorphosis (2025-01-31T21:54:21.942+00:00): https://github.com/endomorphosis/ipfs_accelerate_py/blob/main/ipfs_accelerate_py/worker/skillset/hf_llama.py
- endomorphosis (2025-01-31T21:54:47.79+00:00): and then I need to have the corresponding "skillset" file match each transformers class and make sure that inference works on each of the classes, for all of the hardware platforms
- endomorphosis (2025-01-31T21:55:15.72+00:00): so as you can imagine, it is possible to do by hand, but its more efficient to create a system to automate the code generation
- endomorphosis (2025-01-31T21:55:50.107+00:00): https://github.com/endomorphosis/ipfs_transformers_py/blob/main/ipfs_transformers_py/ipfs_transformers_generator.py
- endomorphosis (2025-01-31T21:56:29.525+00:00): so eventually when I get all of the permutations figured out, it should be something like this, where I enumerate through all the classes, and generate template code, and then test the template code.
- endomorphosis (2025-01-31T21:56:59.906+00:00): now, I'm not really expecting anything on this high of a level from you guys, but I just want you to get your head around software engineering
- endomorphosis (2025-01-31T21:57:50.629+00:00): for this hackathon, im just looking to see how memory efficient I can get the entire voice to voice pipeline, and if i can get it under the 4gb budget
- endomorphosis (2025-01-31T21:58:03.844+00:00): and not have it sound like absolute shit
- endomorphosis (2025-01-31T21:58:57.207+00:00): one of the ideas i have might involve dynamic loading / unloading of the tts / llm model
- ATH🥭 (2025-01-31T22:52:57.311+00:00): if I want to work on something, I should make a branch?  give me a TODO  item and I will do it in the branch.
- endomorphosis (2025-01-31T22:54:35.856+00:00): i think the todo item is to look at https://github.com/endomorphosis/voice_kit_webgpu_cjs
- Lizardperson (2025-01-31T23:57:41.015+00:00): Looked through the code.
- endomorphosis (2025-02-01T00:05:43.272+00:00): whats your status with regards to mounting the iso you just made, and then extracting the files from the iso?
- Lizardperson (2025-02-01T00:06:50.107+00:00): img is on a virtual mount, most important files are off the img and in zfs
- Lizardperson (2025-02-01T00:07:08.847+00:00): I was just about to pull out my old 6 tb and shove the new ones in there.
- endomorphosis (2025-02-01T00:07:49.414+00:00): well, dont you want to make sure that the img is actually readable first?
- endomorphosis (2025-02-01T00:09:15.528+00:00): not only that but just extracting the data, instead of the block by block level copy will save space, and you might not have the space if you start filling the rest of it up with other stuff
- endomorphosis (2025-02-01T00:09:37.213+00:00): i think you should mount that img in read only, and start to copy stuff off of it and onto the main zfs array
- Lizardperson (2025-02-01T00:09:49.205+00:00): That's what I've been doing. With rsync
- Lizardperson (2025-02-01T00:10:35.604+00:00): It's just slow as hell.
- endomorphosis (2025-02-01T00:10:51.9+00:00): yeah, for sure, its probably going to take 2 days or something
- Lizardperson (2025-02-01T00:11:59.23+00:00): Yeah, rsync's documentation is also kinda terrible. I tried like 3-4 different commands to try to make it so it skips copying things that are already in zfs.
- Lizardperson (2025-02-01T00:12:09.475+00:00): Haven't gotten that to work yet.
- Lizardperson (2025-02-01T01:56:35.479+00:00): Ok, old 6tb is out.
- endomorphosis (2025-02-01T01:58:21.648+00:00): okay, let me know if you need any more help with data migration issues
- Lizardperson (2025-02-01T01:59:52.483+00:00): I got it for the most part. Big thing now is porting over my copy of Windows and the new Linux OS over to the 3tb SSD.
- endomorphosis (2025-02-01T02:01:35.406+00:00): okay, we can look at partitioning that ssd in a little bit, but it will have to be tomorrow night or the day after.
- endomorphosis (2025-02-01T02:02:08.449+00:00): I just tried to troubleshoot a motherboard, and tomorrow I will need to try another power supply, by removing the motherboard in my server rack, and trying the motherboard in the server chassis
- Lizardperson (2025-02-01T02:02:17.378+00:00): That's fine. I wanted to get dinner and work on the omni converter tonight.
- endomorphosis (2025-02-01T02:02:20.795+00:00): and if that doesn't work sending the motherboard back to the ebay seller.
- Lizardperson (2025-02-01T02:02:26.081+00:00): Damn
- endomorphosis (2025-02-01T02:04:40.678+00:00): okay, with regards to the omni converter, do you understand that you can pass functions, and that at some point for each converter, you can just pass a dummy function, so for example if you had a pdf parser, you would start by extracting the entire pdf in the form of images, and try to pass a dummy function for tesseract, and pass a dummy function for a visual language model, and then iterate through all the pages, and later i will connect that to the model server, such that we can create a graphrag of an entire folder regardless of the file types, that contain media.
- endomorphosis (2025-02-01T02:05:23.628+00:00): or for example, taking the video clip, and then passing into that a function for ffmpeg, where you will split the video and audio tracks, and then using that to compose the conversion into text.
- endomorphosis (2025-02-01T02:05:57.722+00:00): and then I dont know if you have heard of pydantic, but I had thought about using pydantic to structure the data for knowledge graphs.
- Lizardperson (2025-02-01T02:06:14.389+00:00): I've had to learn pydantic for market agents.
- endomorphosis (2025-02-01T02:07:37.105+00:00): and i honestly haven't even looked at the spreadsheet with the data that you were looking at yet, so I was a bit wary thinking that someone must have already done this
- endomorphosis (2025-02-01T02:07:56.865+00:00): but if it isn't then I suppose it will have to be made or cobbled together from existing parts.
- Lizardperson (2025-02-01T02:08:05.811+00:00): Oh people have done it. But they haven't done it with built in parallelism and concurrency.
- Lizardperson (2025-02-01T02:08:22.353+00:00): Like markitdown is an amazing library, but it's url parsing is based around requests.
- Lizardperson (2025-02-01T02:09:09.361+00:00): and it doesn't support things like threads out of the box
- endomorphosis (2025-02-01T02:09:27.491+00:00): yeah, that is the same case with llama_index and the chunker that was designed by jina_ai, it was not designed for parallelism, so it ends up only using like 10% gpu utilization
- Lizardperson (2025-02-01T02:09:50.654+00:00): Yeah, I'm noticing a lot with these libraries.
- Lizardperson (2025-02-01T02:10:02.071+00:00): They're good at what they do. They just do it really inefficiently.
- endomorphosis (2025-02-01T02:10:27.844+00:00): yeah, thats what the polish is about
- endomorphosis (2025-02-01T02:10:54.408+00:00): sometimes people are like, hey developer hours are expensive and machine hours are cheap, until they get BTFO by some chinese people writing assembly.
- Lizardperson (2025-02-01T02:11:20.764+00:00): I mean, new features are exciting and flashy.
- Lizardperson (2025-02-01T02:11:32.59+00:00): But if it can't scale
- endomorphosis (2025-02-01T02:11:46.028+00:00): yeah, but its like, if I have VC, I can just afford to spin up 10x as many gpus, with no problem
- Lizardperson (2025-02-01T02:12:32.494+00:00): that's... so wasteful.
- Lizardperson (2025-02-01T02:12:52.523+00:00): Just hire a dev to optimize the code for like 70k+ a year.
- Lizardperson (2025-02-01T02:13:12.346+00:00): Cheaper than getting a few A100s or H100s.
- Lizardperson (2025-02-01T02:14:37.631+00:00): more environmentally friendly as well.
- Lizardperson (2025-02-01T02:14:47.724+00:00): guess Im preaching to the choir though
- endomorphosis (2025-02-01T03:02:22.766+00:00): qualcomm guy
- endomorphosis (2025-02-02T20:06:09.805+00:00): I got the attention of this person, who I got to join the Yannic Kilcher Discord weekend paper discussion about deepseek, and discuss about the ipfs transformers decentralization aspects, in addition to the US government sanctions against chinese ownership of tiktok.
- endomorphosis (2025-02-02T20:07:02.49+00:00): https://github.com/endomorphosis/hallucinate_app/wiki/IPFS-HuggingFace-Bridge-Architecture
- endomorphosis (2025-02-02T20:07:07.203+00:00): updated the wiki
- endomorphosis (2025-02-02T20:07:26.773+00:00): and I got about half way though moving all the test functions to another folder / class
- endomorphosis (2025-02-02T20:08:43.91+00:00): I need to disassemble a motherboard / server, test a motherboard,  and reassemble it again today, and I hope to have gotten through moving  all of my tests to a new file, which can be better hooked into some sort of testing framework / ai maintainance system.
- endomorphosis (2025-02-04T07:57:01.318+00:00): https://github.com/endomorphosis/ipfs_accelerate_py/tree/main/ipfs_accelerate_py/test
- endomorphosis (2025-02-04T07:57:51.99+00:00): i have been setting up tests, so that i can do test driven development, and have the AI iterate through which models work or dont, and how to use the error handling to automatically fix code with the AI loop.
- endomorphosis (2025-02-04T07:58:51.784+00:00): likewise getting api backends setup https://github.com/endomorphosis/ipfs_accelerate_py/tree/main/ipfs_accelerate_py/api_backends
- endomorphosis (2025-02-04T07:59:14.415+00:00): and I have been working on getting a LLC bank account setup and funded with 50k
- endomorphosis (2025-02-04T07:59:37.543+00:00): its always some other hoop i have to jump through with the bank and KYC
- endomorphosis (2025-02-04T08:01:41.285+00:00): https://github.com/endomorphosis/ipfs_accelerate_py/blob/main/ipfs_accelerate_py/test/huggingface_model_types.json there are 286 huggingface model types, and instead of writing a "skillset" file for each one, I am going to use some sort of search + rag + code tracing, to try to automatically write the skills such as
- endomorphosis (2025-02-04T08:02:20.6+00:00): https://github.com/endomorphosis/ipfs_accelerate_py/blob/main/ipfs_accelerate_py/worker/skillset/hf_bert.py
- endomorphosis (2025-02-04T08:04:27.46+00:00): i saw this code from @ATH🥭  but it looks like its a bare skeleton, https://github.com/endomorphosis/voice_kit_webgpu_cjs/tree/ath-dev

I also noticed placeholder code for gemma, and I didn't know if you realized that I was going to try to use the transformers.js models + rag for the entire pipleline
- ATH🥭 (2025-02-04T08:09:26.232+00:00): Yea I'm going to scrap that whole branch. I just wanted to get in there and move stuff around as I haven't been pushing commits lately
- endomorphosis (2025-02-04T08:09:54.079+00:00): ok
- ATH🥭 (2025-02-04T08:10:34.091+00:00): Can I watch while you do all this?
- ATH🥭 (2025-02-04T08:26:14.878+00:00): We can keep it casual. 😁 If you're working on it and you feel like streaming it AND pinging me then I will be there for it.
- Lizardperson (2025-02-04T21:59:17.566+00:00): @endomorphosis I want to get a jump on this before I start throwing myself at the omni-converter. Do you have a roadmap or anything that needs to get done ASAP?
- endomorphosis (2025-02-04T22:15:00.231+00:00): "I was intending on this to be the source of ML model inference that powers the omni converter, so you should look in the repository for the huggingface classes, so you should make a class for each model type that should take as input the splitter, it should have a "source" and a "drain", and then the splitter should take input from the source, and the models should send it to a drain, so that it can be reassembled into text.
- endomorphosis (2025-02-04T22:15:11.222+00:00): e.g. videos, pdfs, etc.
- Lizardperson (2025-02-05T00:30:25.711+00:00): Many of the conversions don't need LLMs to accomplish, and the library itself uses APIs to OpenAI to do its LLM work. And what do you mean by splitter? Like where to route the input files?
- Lizardperson (2025-02-05T00:32:09.538+00:00): Also, why not just have some sort of API that can access local backends like ollama, aphrodite, etc. instead of running it within the converter itself?
- Lizardperson (2025-02-05T00:32:49.085+00:00): Afaik they all have API port options available.
- endomorphosis (2025-02-05T00:57:36.308+00:00): I'll address this in a moment, but I just got home
- Lizardperson (2025-02-05T00:57:45.554+00:00): np!
- endomorphosis (2025-02-05T01:22:42.781+00:00): https://github.com/endomorphosis/ipfs_accelerate_py/tree/main/ipfs_accelerate_py/api_backends
- endomorphosis (2025-02-05T01:22:58.373+00:00): https://github.com/endomorphosis/ipfs_accelerate_py/tree/main/ipfs_accelerate_py/container_backends
- endomorphosis (2025-02-05T01:24:10.603+00:00): yeah, this is meant to multiplex connections such that you can mix local inference, api inference, or even spin up containers, but not all features are complete, and I have an old container backend that I need to migrate from the old mlops platform.
- endomorphosis (2025-02-05T01:24:34.01+00:00): https://github.com/endomorphosis/ipfs_accelerate_py/tree/main/ipfs_accelerate_py/worker/skillset
- endomorphosis (2025-02-05T01:24:54.492+00:00): the tests are going to be used to run / debug / write files in this directory.
- endomorphosis (2025-02-05T01:25:17.711+00:00): I am going to use the openai api to create the loop that controls the automation of that
- endomorphosis (2025-02-05T01:25:54.889+00:00): the template file will be "default.py"
- endomorphosis (2025-02-05T01:27:59.047+00:00): then I'll do some sort of RAG of the transformers documentation, and also grab the api and class definition, and see if I can get the llm to fix the template until the input / ouput works
- endomorphosis (2025-02-05T01:28:55.475+00:00): now as far as your module goes, your module needs to decide what huggingface transformers classes you want to compose, that will transform whatever is inside of it into text, that can be put into the language model.
- endomorphosis (2025-02-05T01:30:30.064+00:00): and ideally, some text data, which will be the most amenable to analysis / convertion to a knowledge graph
- Lizardperson (2025-02-05T02:04:20.328+00:00): Will probably be literally just a basic Llava model or deepseek vl, and whisper.
- Lizardperson (2025-02-05T02:05:32.764+00:00): There will be spots for all the others, but I can't support every model right off the bat. I don't have a good way to automate the coding of these classes yet, and testing them all will take time.
- Lizardperson (2025-02-05T02:06:44.556+00:00): Source/drain concept will work nicely though. Duckdb to prevent machines from stepping on each others toes with inputs
- ATH🥭 (2025-02-05T03:13:38.617+00:00): https://huggingface.co/papers/2501.18119
- ATH🥭 (2025-02-05T03:14:08.252+00:00): Is this useful?
- endomorphosis (2025-02-05T03:14:35.193+00:00): no, i am not nearly there yet.
- endomorphosis (2025-02-05T03:15:02.844+00:00): the duckdb files can be converted into a CAR file and uploaded to ipfs and given a CID to share with other peers.
- endomorphosis (2025-02-05T03:15:30.331+00:00): https://github.com/endomorphosis/ipfs_parquet_to_car_js/tree/main/ipfs_parquet_to_car_js
- endomorphosis (2025-02-05T03:16:03.597+00:00): https://discord.com/channels/1247475892435816553/1334559930929119293/1336126396371566683
- endomorphosis (2025-02-05T05:15:37.646+00:00): yeah, so kind of what i was thinking, is like if you had some whisper + diarization need, that you can inject the model server "ipfs_accelerate" into a project such as 
https://github.com/m-bain/whisperX/blob/44e8bf5bb658ad6e1a80585b987fae2d48b9662c/whisperx/asr.py#L10
```
import ctranslate2
import faster_whisper
import numpy as np
import torch
from faster_whisper.tokenizer import Tokenizer
from faster_whisper.transcribe import TranscriptionOptions, get_ctranslate2_storage
from transformers import Pipeline
from transformers.pipelines.pt_utils import PipelineIterator
```
and replacing that with some steps using inherited api endpoints created from the ipfs_accelerate_py model manager, but for now, it doesn't need to be abled, and maybe just swallow it with a conditional
```
legacy_mode = True
if legacy_mode == True:
  original_code()
else:
  ipfs_accelerate_py.init_endpoint("faster_whisper")
```
- Lizardperson (2025-02-05T07:46:27.34+00:00): I'll fine a way to incorporate it into my codebase as I go. The duckdb part is primarily to avoid having to create a million on-disk markdown files right off the bat. I'm trying to get into the habit of document/test-driven development.
- endomorphosis (2025-02-05T07:59:42.182+00:00): do you know about how to get files in duck db converted to parquet?
- Lizardperson (2025-02-05T08:10:06.913+00:00): I've been reading through the docs, so yes. But I haven't done it in code. Hell, I've never even used parquet files before.
- Lizardperson (2025-02-05T08:10:14.086+00:00): first time for everything though
- endomorphosis (2025-02-05T08:40:48.575+00:00): okay sounds good, and then I have a converter, that converts the parquet files to IPFS car files.
- endomorphosis (2025-02-05T08:41:18.978+00:00): and then when you have that car file, you get an IPFS cid string, to retrieve it peer to peer
- endomorphosis (2025-02-05T08:42:58.621+00:00): so, like a good idea that I find with regards to the sink / source problem, is that you can throw all sorts of stuff in queues, but you can deterministically generate a IPFS hash of the value that you start with, and let that be the "tag" that follows the data from the source to the sink, as it follows through the transformation pipeline
- endomorphosis (2025-02-05T09:33:05.741+00:00): https://github.com/endomorphosis/ipfs_accelerate_py/tree/main/ipfs_accelerate_py/
- endomorphosis (2025-02-05T09:33:21.662+00:00): more updates
- endomorphosis (2025-02-05T09:33:51.329+00:00): https://github.com/endomorphosis/ipfs_accelerate_py/tree/main/ipfs_accelerate_py/api_backends
- endomorphosis (2025-02-05T17:19:10.994+00:00): @ATH🥭
- endomorphosis (2025-02-06T17:33:23.233+00:00): https://custom.cvent.com/FA0DA8770B6F4377BD1A37B2B2BDE8E5/files/40dfa8e81a464c7fa38560ea037a6d3a.pdf
- endomorphosis (2025-02-06T19:44:38.066+00:00): @ATH🥭 what is your developer environment, also do you want to use an AI PC from Intel, which has a "neural processing unit", in their online device cloud.
- ATH🥭 (2025-02-06T21:54:31.356+00:00): My dev environment is my local network with a 6gb and a 3gb graphics card. Yes, please.
- endomorphosis (2025-02-06T21:55:51.657+00:00): https://console.cloud.intel.com/home?region=us-region-2
- endomorphosis (2025-02-06T21:56:05.85+00:00): i'll just give you my credentials
- endomorphosis (2025-02-06T21:57:52.427+00:00): user: starworks5@gmail.com
password: U8C%zKVRX*gy5rJ
- endomorphosis (2025-02-06T21:58:08.11+00:00): https://tiber-192-55-48-217.eglb.intel.com/guacamole/#/client/NzUyMwBjAG15c3Fs
- endomorphosis (2025-02-06T21:58:32.364+00:00): this will work only today, but try it out and tell me if the remote desktop works good enough, so that the lag isn't overwhelming
- endomorphosis (2025-02-06T22:00:19.145+00:00): poast your dev environment
- ATH🥭 (2025-02-06T22:07:03.025+00:00): How? You want to know the specs of my devices? I will do that. I'm not sure exactly what you're asking.
- endomorphosis (2025-02-06T22:07:18.139+00:00): yeah, your main developer environment
- endomorphosis (2025-02-06T22:07:56.63+00:00): also were you able to get to the remote desktop
- endomorphosis (2025-02-06T22:08:23.433+00:00): i need you to tell me how bad the lag is on the remote desktop for you
- ATH🥭 (2025-02-06T22:11:30.89+00:00): there is no lag in the remote desktop environment
- endomorphosis (2025-02-06T22:13:09.736+00:00): okay, so I can ask for like a 2 week reservation for one of these laptops
- endomorphosis (2025-02-06T22:13:29.129+00:00): but I am supposed to give them some lead time on that.
- endomorphosis (2025-02-06T22:13:51.764+00:00): and otherwise I'm not paying you right now, and I have been dealing with the bank
- ATH🥭 (2025-02-06T22:14:26.208+00:00): 🫡
- ATH🥭 (2025-02-06T22:15:05.404+00:00): I have a lot of old devices.  should I compile a list of all of them?  I don't know what a dev environment is.
- endomorphosis (2025-02-06T22:15:44.827+00:00): the workstation that you write code on every day.
- ATH🥭 (2025-02-06T22:16:40.065+00:00): I have an expired passport ... what is this?
- endomorphosis (2025-02-06T22:19:31.735+00:00): my partner and I putting 50k in the bank
- endomorphosis (2025-02-06T22:20:36.286+00:00): we used to pay the old Jr Dev out of Tigmar GMBH, but his accountant quit, and now Manuel Otto is doing all of his own accounting and moving the records over to digital format, and we have setup two LLCs in the USA for doing business and paying people / bills
- endomorphosis (2025-02-06T22:20:49.497+00:00): Worldwide Software LLC and Hallucinate LLC
- endomorphosis (2025-02-06T22:22:14.728+00:00): so, im not trying to tie you down with promises until I can actually afford to pay you for work, but also I really hate if you are working on a garbage bin PC, that cant even load an AI model
- endomorphosis (2025-02-06T22:23:19.079+00:00): I would like to get alot of the code I've been doing in python translated to nodejs / client js, so that it works with web neural networks.
- endomorphosis (2025-02-06T22:23:53.785+00:00): and from the javascript side of things, being able to run the same code in the browser, that runs on the server
- endomorphosis (2025-02-06T22:24:39.985+00:00): so if grandma's ipad cant do good webnn inference, I can literally just get a remote tunnel to a container running the webnn code in the cloud.
- endomorphosis (2025-02-06T22:25:33.117+00:00): and in general my flow is to prototype in python, before translating in javascript, because its harder going in the reverse direction
- ATH🥭 (2025-02-06T22:31:43.259+00:00): my dev env is dog water.  I write code on a chromebook that  I can't find the specs of anymore and a PC I built in 2017.
- ATH🥭 (2025-02-06T22:31:45.224+00:00): XD
- endomorphosis (2025-02-06T22:32:12.928+00:00): what is the PC that you built in 2017 like?
- ATH🥭 (2025-02-06T22:33:44.001+00:00): stby
- ATH🥭 (2025-02-06T22:38:08.861+00:00): 😎
- endomorphosis (2025-02-06T22:41:33.268+00:00): okay, i see that you are somewhat compute limited, but you should be able to load alot of the small models in gpu, and the 4GB was the floor that I was setting for those people who had "legacy" gpu builds, but I think I can promise you $500 for helping me during the hackathon, because that is how much spare cash i have in my personal account.
- ATH🥭 (2025-02-06T22:42:24.598+00:00): no need to pay me for hackathon. pay me if we win.
- endomorphosis (2025-02-06T22:42:26.248+00:00): but thats like maybe 1 weeks worth of work even for an intern
- endomorphosis (2025-02-06T22:42:46.873+00:00): nah, its called "minimum wage" law dude
- endomorphosis (2025-02-06T22:43:03.172+00:00): what kind of douche asks people to work for free
- endomorphosis (2025-02-06T22:45:03.279+00:00): however, if you want to be "cool" or whatever you're always welcome to spend the $500 on equipment instead of Ramen.
- endomorphosis (2025-02-06T22:45:18.862+00:00): or like cocaine
- endomorphosis (2025-02-06T22:45:52.609+00:00): but TBH your motherboard is pretty much a cheap one
- endomorphosis (2025-02-06T22:46:03.654+00:00): you would be better off saving up for a nvidia 3090
- Lizardperson (2025-02-06T22:55:40.681+00:00): Can confirm, 3090s are pretty sweet.
- Lizardperson (2025-02-06T22:55:50.533+00:00): If only they had more VRAM
- ATH🥭 (2025-02-06T22:56:07.105+00:00): yep yep yep. I need a 3090
- ATH🥭 (2025-02-06T22:57:44.896+00:00): https://pcpartpicker.com/trends/price/video-card/#gpu.chipset.geforce-rtx-3090
- ATH🥭 (2025-02-07T01:48:38.631+00:00): im writing useful code. maybe for the first time in my life
- Lizardperson (2025-02-07T01:49:31.895+00:00): I'm software engineering. So I don't get caught in ruts like I usually do.
- ATH🥭 (2025-02-07T01:49:46.713+00:00): agentic project management pipeline
- endomorphosis (2025-02-07T02:05:19.081+00:00): well let me know when you actually get started on the transformer.js stuff
- endomorphosis (2025-02-07T02:09:07.017+00:00): what is this for?
- Lizardperson (2025-02-07T02:09:40.05+00:00): Omni-converter.
- endomorphosis (2025-02-07T02:11:05.994+00:00): well, I was hoping that how it would work, is that you have file "preprocessor", and the processor has a defined input check, and a defined set output datatypes, that are "children" of the original, then the "children" get fed back through and they too might be given children, if they are somehow split up
- endomorphosis (2025-02-07T02:12:30.409+00:00): then finally when the "childrens children" make it past the filtering meant to sieve out the individual composite datatypes (e.g. frames of a video, waveforms, captions, etc), only the primitive types can "fall through"
- endomorphosis (2025-02-07T02:12:56.299+00:00): then they are sort of "collected" and then "reassembled" with because they are tagged with their parent content ID
- endomorphosis (2025-02-07T02:13:26.03+00:00): but when they are reassembled, they are reassembled as text / json / pydantic pieces, that can be summarized or vector searched.
- Lizardperson (2025-02-07T02:14:18.633+00:00): I will say, this is a top level overview. All of what you're talking about would likely occur in the Core section.
- endomorphosis (2025-02-07T02:14:51.363+00:00): okay, im not trying to micromanage, but in general this is the best way to attack a problem like this
- Lizardperson (2025-02-07T02:15:02.861+00:00): The Core will hopefully be agnostic enough to allow for that process.
- Lizardperson (2025-02-07T02:15:25.911+00:00): I'm honestly having trouble picturing what exactly you're trying to get across.
- endomorphosis (2025-02-07T02:15:38.107+00:00): yeah, im hoping I can just bolt on the model server, then you can grab whatever ml models that you used to invoke in your script, instead later from the model server.
- endomorphosis (2025-02-07T02:17:33.833+00:00): I want to shred up the original files into little pieces, and then convert them all into small text pieces
- endomorphosis (2025-02-07T02:17:57.127+00:00): so that I can search over them with a search engine
- Lizardperson (2025-02-07T02:18:46.555+00:00): That I think can be accomplished for some kinds of files, like videos, things with pages or sections (Excel file, pdf pages).
- Lizardperson (2025-02-07T02:19:08.334+00:00): Within each converter, there can be a module that splits them up.
- endomorphosis (2025-02-07T02:19:11.637+00:00): yeah, exactly, im not expecting a text summary of a video game, or anything
- endomorphosis (2025-02-07T02:20:27.142+00:00): well, each "converter" is an AI model, and the document needs to be converted from its base parts, into its pieces, for example a .xls file might have to have each of its spreadsheets split apart and looked at individually
- endomorphosis (2025-02-07T02:21:01.304+00:00): and im not even asking for anything nearly perfect, just start with videos and pdfs right now if you can
- endomorphosis (2025-02-07T02:21:21.856+00:00): or pdfs, ppts, and xls
- endomorphosis (2025-02-07T02:21:59.433+00:00): but as long as you get started with the right way, that will make it easy to scale compute and add filetypes modularly.
- Lizardperson (2025-02-07T02:22:19.266+00:00): Each converter is most definitely *not* an AI model. AI models will definitely be used, but more as a resource to be consumed and released, rather than used for every single document.
- endomorphosis (2025-02-07T02:22:22.398+00:00): then I can add whatever vanity filetype I want later.
- endomorphosis (2025-02-07T02:22:39.44+00:00): well, I dont know what you mean by a "converter" and a "parser"
- endomorphosis (2025-02-07T02:23:00.823+00:00): a ml model is a "function" that computes from one data type to another data type
- endomorphosis (2025-02-07T02:24:27.956+00:00): also converting from a string to a float is called "casting"
- endomorphosis (2025-02-07T02:24:36.754+00:00): and reassembling all the bits is "compiling"
- Lizardperson (2025-02-07T02:26:17.68+00:00): I'm defining converter as a function that turns one document format into another. In this case, the output of a single converter *is* markdown text, full stop. I'm defining parsers as the how for how to do that markdown conversion, whether that involve LLMs, non-LLMs, or some other process.
- Lizardperson (2025-02-07T02:27:01.616+00:00): There will most likely be multiple parsers that can be chosen based on flowcharts, like for Presentational Excel files, flat vs Non-Flat PDFs.
- endomorphosis (2025-02-07T02:27:50.182+00:00): yeah, i just want you to keep in mind when you're thinking the process through, that there might be multiple huggingface classs, and huggingface models that can convert from one type to another type, and that to some degree users will have both a preference but also a selection alraedy in their local host.
- Lizardperson (2025-02-07T02:28:28.705+00:00): That's why I'm leaning towards APIs for the LLMs, along with metadata, rather than have it in the program directly.
- endomorphosis (2025-02-07T02:28:33.908+00:00): I was thinking that it might be useful to keep track of the huggingface classes, and the datatypes that they map to
- endomorphosis (2025-02-07T02:29:10.356+00:00): e.g . clip tokenizers goes from text -> tensor[x,y] dimensions (i forgot the exact number), etc
- Lizardperson (2025-02-07T02:29:47.736+00:00): So long as I can define it as a resource to be used, it can go in the pool.
- Lizardperson (2025-02-07T02:30:31.742+00:00): So things can be allocated dynamically as a document goes through the Core pipeline.
- endomorphosis (2025-02-07T02:31:55.144+00:00): a UML diagram is often so vague that its often not helpful, but I want to sort of communicate, that if you define the document processor, and the models, in terms of their inputs and their outputs, such that there is some easy way to play matchmaker between what models the user has on their system right now, and what models get used to convert the document into a form that is digestable by a llm or vector search
- endomorphosis (2025-02-07T02:32:25.237+00:00): anyways, I have my own work to do today, and the people at storacha seemed to need some work done backing up 18TB of government data to filecoin
- Lizardperson (2025-02-07T02:32:39.209+00:00): Alright
- Lizardperson (2025-02-07T02:32:41.361+00:00): Thanks btw
- endomorphosis (2025-02-07T03:20:05.303+00:00): why isn't this on git?
- endomorphosis (2025-02-07T03:20:22.248+00:00): ill look at it later, right now I'm writing other code
- endomorphosis (2025-02-07T05:16:42.619+00:00): https://github.com/endomorphosis/ipfs_accelerate_py/tree/main/ipfs_accelerate_py/api_backends
https://github.com/endomorphosis/ipfs_accelerate_py/blob/main/ipfs_accelerate_py/api_backends/apis.py
- endomorphosis (2025-02-07T05:17:00.426+00:00): i just templated out how all the apis will be connected, and the tests for them.
- endomorphosis (2025-02-07T05:17:23.159+00:00): https://github.com/endomorphosis/ipfs_accelerate_py/blob/main/ipfs_accelerate_py/test/test_api_backend.py
- ATH🥭 (2025-02-07T08:19:51.974+00:00): https://github.com/MeDott29/voice-extension
dont look. it's hideous.
- endomorphosis (2025-02-07T17:42:57.494+00:00): I just now checked it, its basically a recording widget, and I wonder whether you had actually taken from the three source files as I asked and tried to merge them.
- ATH🥭 (2025-02-07T19:16:40.87+00:00): I'm going to put together a project document. Then we can do a 5-10 minute call later at your earliest convenience? I need tasks broken up into tiny measurable goals.
- endomorphosis (2025-02-07T19:19:19.711+00:00): okay